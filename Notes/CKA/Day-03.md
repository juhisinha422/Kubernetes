Day 3 (Journey to CKA)

Todayâ€™s Topic: Kube-Scheduler

A common misconception ğŸ‘‰ The scheduler doesnâ€™t actually run or place the pod on the node.
It only decides the best node for a pod to run on.

The actual placement & execution is handled by the Kubelet on that node. âœ…

ğŸ”¹ How does the Scheduler decide?
The scheduler looks at each pending pod and tries to find the â€œbest fitâ€ node for it, based on:

Resource requirements (CPU, Memory, GPU etc.)

Node selectors (explicit matching rules)

Taints & Tolerations (to restrict or allow workloads on certain nodes)
Node affinity / anti-affinity (keep pods together or spread across nodes)

Pod affinity / anti-affinity (influence pod placement based on other pods)

Topology spread constraints (to evenly spread pods across zones/nodes)

ğŸ”¹ The Process in 2 Steps:

1ï¸âƒ£ Filtering (Predicates): First, the scheduler filters out nodes that cannot run the pod. (Example: node doesnâ€™t have enough CPU).

2ï¸âƒ£ Scoring (Priorities): Then, it ranks the remaining nodes and picks the highest-scoring node.

ğŸ“Œ Example:

If you request a pod with 2 CPU and 2 GB memory, the scheduler will:
Filter out nodes that donâ€™t have that much free space

Among the remaining, pick the one with the best score based on affinity, spreading rules, etc.

ğŸ‘‰ In short, the Kube-Scheduler = The â€œmatchmakerâ€ between pods and nodes 


![Image](https://github.com/user-attachments/assets/82a3fe2b-8678-477d-956c-4704791b8c1d)

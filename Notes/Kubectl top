Most people use kubectl top without thinking about whatâ€™s happening behind the scenes.

But how does Kubernetes actually show live CPU and memory usage?

Letâ€™s break it down ğŸ‘‡

When you install Metrics Server, it does not directly â€œcalculateâ€ resource usage itself.

Hereâ€™s what actually happens:

1ï¸âƒ£ Every node runs a Kubelet.
2ï¸âƒ£ Inside Kubelet, thereâ€™s a component called ğ—°ğ—”ğ—±ğ˜ƒğ—¶ğ˜€ğ—¼ğ—¿ (ğ—–ğ—¼ğ—»ğ˜ğ—®ğ—¶ğ—»ğ—²ğ—¿ ğ—”ğ—±ğ˜ƒğ—¶ğ˜€ğ—¼ğ—¿).
cAdvisor collects real-time container-level CPU and memory metrics directly from the container runtime.
3ï¸âƒ£ Metrics Server queries each Kubeletâ€™s /ğ—ºğ—²ğ˜ğ—¿ğ—¶ğ—°ğ˜€/ğ—¿ğ—²ğ˜€ğ—¼ğ˜‚ğ—¿ğ—°ğ—² endpoint over HTTPS.
4ï¸âƒ£ Kubelet exposes the usage data it gets from cAdvisor.
5ï¸âƒ£ Metrics Server aggregates this data and exposes it through the Kubernetes Metrics API (metrics.k8s.io).

Now when you run:

 â€¢ kubectl top pods
 â€¢ kubectl top nodes


kubectl queries the Kubernetes API server â†’ which fetches data from Metrics Server â†’ which collected it from Kubelets â†’ which got it from cAdvisor.

Thatâ€™s the full flow.

Important:
Metrics Server is designed for autoscaling (HPA/VPA), not long-term monitoring. It keeps only short-term metrics and does not store historical data.

Your stateful Kubernetes services just broke after an upgrade!

As a DevOps engineer, Iâ€™ve seen this nightmare scenario destroy weekends in production. When StatefulSets fail post-upgrade, every minute of downtime costs money.

Hereâ€™s my 7-step Kubernetes debugging playbook:

ğŸ‘‰ Step 1: Verify the obvious
ğŸ”º `kubectl get pods -n namespace` â†’ Are pods actually running?
ğŸ”º `kubectl get statefulsets -n namespace` â†’ Check replica counts
ğŸ”º `kubectl describe pod pod-name` â†’ Look for crash loops or image pull errors

ğŸ‘‰ Step 2: Hunt through Kubernetes events
ğŸ”º `kubectl get events --sort-by=.metadata.creationTimestamp` â†’ Recent cluster events
ğŸ”º `kubectl describe statefulset statefulset-name` â†’ Deployment-specific issues

ğŸ‘‰ Step 3: Check persistent volume issues
ğŸ”º `kubectl get pv,pvc -n namespace` â†’ Volume binding problems
ğŸ”º `kubectl describe pvc pvc-name` â†’ Storage provisioning failures
ğŸ”º `kubectl get storageclass` â†’ Storage class compatibility after upgrade

ğŸ‘‰ Step 4: Investigate resource consumption
ğŸ”º `kubectl top pods -n namespace` â†’ Memory/CPU limit breaches
ğŸ”º `kubectl describe node node-name` â†’ Node resource exhaustion
ğŸ”º `kubectl get events | grep -i "failed.*schedule"` â†’ Pod scheduling failures

ğŸ‘‰ Step 5: Find networking and service issues
ğŸ”º `kubectl get svc,endpoints -n namespace` â†’ Service connectivity
ğŸ”º `kubectl describe service service-name` â†’ Load balancer problems
ğŸ”º `kubectl get networkpolicies` â†’ Network policy blocking traffic

ğŸ‘‰ Step 6: Track configuration and secrets
ğŸ”º `kubectl get configmap,secret -n namespace` â†’ Missing configurations
ğŸ”º `kubectl describe pod pod-name | grep -i "mount"` â†’ Volume mount failures
ğŸ”º `kubectl get pod pod-name -o yaml` â†’ Compare with previous working config

ğŸ‘‰ Step 7: Real-time debugging
ğŸ”º `kubectl logs -f pod-name --previous` â†’ Previous container crash logs
ğŸ”º `kubectl exec -it pod-name -- /bin/bash` â†’ Live container inspection
ğŸ”º `kubectl port-forward pod-name 8080:8080` â†’ Direct pod connectivity testing

The key is following this systematically rather than randomly trying kubectl commands.

Whether you manage EKS, GKE, or on-premises clusters, this debugging flow works universally.

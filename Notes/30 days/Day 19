ğŸ”„ ğ——ğ—®ğ˜† ğŸ­ğŸµ: ğ—¥ğ—¼ğ—¹ğ—¹ğ—¶ğ—»ğ—´ ğ—¨ğ—½ğ—±ğ—®ğ˜ğ—²ğ˜€ ğ—®ğ—»ğ—± ğ—¥ğ—¼ğ—¹ğ—¹ğ—¯ğ—®ğ—°ğ—¸ğ˜€ ğ—¶ğ—» ğ—ğ˜‚ğ—¯ğ—²ğ—¿ğ—»ğ—²ğ˜ğ—²ğ˜€
Welcome to Day 19 of our Kubernetes series! Yesterday, we looked at autoscaling with HPA. Today, we're shifting gears to something equally critical for application lifecycle management â€” Rolling Updates and Rollbacks.

Letâ€™s talk about safe deployments, zero downtime, and quick recovery.

ğŸš€ ğ—ªğ—µğ—®ğ˜ ğ—œğ˜€ ğ—® ğ—¥ğ—¼ğ—¹ğ—¹ğ—¶ğ—»ğ—´ ğ—¨ğ—½ğ—±ğ—®ğ˜ğ—²?
When you update your application (like deploying a new container image), Kubernetes doesn't take down all your pods at once. Instead, it gradually replaces old pods with new ones, ensuring there's always a minimum number of healthy instances running.
This approach is called a Rolling Update.

Benefits:
 â€¢ Zero downtime deployments
 â€¢ Controlled rollout speed
 â€¢ Automatic health checks during deployment

ğŸ•¹ï¸ ğ—›ğ—¼ğ˜„ ğ—œğ˜ ğ—ªğ—¼ğ—¿ğ—¸ğ˜€
Kubernetes handles rolling updates by:
 â€¢ Launching new pods with the updated spec
 â€¢ Waiting for them to become healthy
 â€¢ Gradually terminating the old pods

You can control the process using deployment settings like:
 â€¢ MaxUnavailable: How many old pods can be down during the update
 â€¢ MaxSurge: How many extra new pods can run temporarily

âª ğ—ªğ—µğ—®ğ˜ ğ—”ğ—¯ğ—¼ğ˜‚ğ˜ ğ—¥ğ—¼ğ—¹ğ—¹ğ—¯ğ—®ğ—°ğ—¸ğ˜€?
Not every update goes as planned.
If something goes wrong â€” say your app crashes or a bug sneaks in â€” Kubernetes lets you roll back to the previous version instantly.

With a simple command or API call, Kubernetes will:
 â€¢ Revert the deployment to the last known good configuration
 â€¢ Reapply the old pod template
 â€¢ Restart the rollout process safely

ğŸ” ğ—ªğ—µğ˜† ğ—§ğ—µğ—¶ğ˜€ ğ— ğ—®ğ˜ğ˜ğ—²ğ—¿ğ˜€ ğ—¶ğ—» ğ—£ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜ğ—¶ğ—¼ğ—»
 â€¢ You get safe and predictable deployments
 â€¢ Issues can be quickly rolled back without downtime
 â€¢ Teams can adopt CI/CD pipelines with confidence
